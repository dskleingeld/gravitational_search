Many fields depend on good optimization techniques. Metaheuristics commonly used are Particle Swarm Optimization and Simulated Annealing. There is no best meta heuristic for all existing problems. In 2009 a new algorithm inspired by the physics of gravity: the \ac{gsa} was introduced\cite{GSA}. 

In \ac{gsa} there are multiple particles spread over the parameter space of the optimization problem. They each have a fitness given the optimization problem with their individual parameters. We can see that fitness as their mass. Newtons second law and his law of gravitation is then used to determine how these particles move at the next time step. For \ac{gsa} to work best the law of gravitation is modified and some randomness is introduced.

\ac{gsa} is weak in its local search ability to improve this \ac{gabsa} was created. It uses simulated annealing to improve the local search ability \cite{GABSA}. Here I attempt to reproduce some of the results from the \ac{gabsa} paper. However as there is no publicly available source for \ac{gabsa} I will first implement \ac{gsa} before extending it with \ac{gabsa}. 

This report discusses my implementation of \ac{gsa} and \ac{gabsa}, shows how my implementations perform compared to the cited papers before discussing the performance and finally concluding if this replicates the results of the papers.
